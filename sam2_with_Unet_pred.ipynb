{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b151eade-8d6d-43d2-ad03-705ab84e088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import transform\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "406135ea-8d3a-44e5-b7b9-58491776335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_s3_uri):\n",
    "    \"\"\"Load an image from S3 and convert it to a NumPy array.\"\"\"\n",
    "    # Open the image using rasterio\n",
    "    with rasterio.open(image_s3_uri) as src:\n",
    "        # Read the image data\n",
    "        image = src.read()  # This will read all the bands\n",
    "        image = np.moveaxis(image, 0, -1)  # Move channels to the last dimension\n",
    "        image = image[:, :, :3]  # Assuming you want to use only the first 3 bands (R, G, B)\n",
    "        image_normalized = (image - np.min(image)) / (np.max(image) - np.min(image)) * 255\n",
    "        image_normalized = image_normalized.astype(np.uint8)\n",
    "    return image_normalized\n",
    "\n",
    "\n",
    "def load_annotations(annotation_s3_uri,Model_Latestimage_filename):\n",
    "    \"\"\"Load annotations for a specific image from a JSON file on S3.\"\"\"\n",
    "    fs = s3fs.S3FileSystem()\n",
    "    with fs.open(annotation_s3_uri, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    for img in data['images']:\n",
    "        if img['file_name'] == image_filename:\n",
    "            return img['annotations']\n",
    "    return None\n",
    "    \n",
    "def load_original_annotations(annotation_s3_uri):\n",
    "    \"\"\"Load annotations for a specific image from a JSON file on S3.\"\"\"\n",
    "    fs = s3fs.S3FileSystem()\n",
    "    with fs.open(annotation_s3_uri, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def polygon_to_mask(polygon, width, height):\n",
    "    mask = Image.new('L', (width, height), 0)\n",
    "    ImageDraw.Draw(mask).polygon(polygon, outline=1, fill=1)\n",
    "    return torch.tensor(np.array(mask), dtype=torch.float32)\n",
    "\n",
    "\n",
    "def convert_to_binary_masks(predicted_masks):\n",
    "    \"\"\"\n",
    "    Converts boolean masks from SAM2's output to binary masks.\n",
    "\n",
    "    Args:\n",
    "    - predicted_masks (list of dict): List of predicted masks with 'segmentation' key containing boolean arrays.\n",
    "\n",
    "    Returns:\n",
    "    - binary_masks (list of np.array): List of binary masks (1 and 0).\n",
    "    \"\"\"\n",
    "    binary_masks = []\n",
    "    for mask_data in predicted_masks:\n",
    "        # Convert the boolean segmentation mask to an integer binary mask\n",
    "        binary_mask = mask_data['segmentation'].astype(np.uint8)\n",
    "        binary_masks.append(binary_mask)\n",
    "    \n",
    "    return binary_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5fea694-5ff6-461b-a820-f71420d7235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Json\n",
    "import s3fs\n",
    "import json\n",
    "train_annotation_s3_uri = 's3://solafune/train_annotation.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffc3b10-d4cb-4383-99b7-13efa8e6a12c",
   "metadata": {},
   "source": [
    "# Building the U-net And Predicting the Input Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89fdf94b-a3f4-43de-af38-9209597a1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),  # Batch Normalization\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),  # Batch Normalization\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Down, self).__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super(Up, self).__init__()\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = nn.Sequential(DoubleConv(n_channels, 64), nn.Dropout(0.5))  # Added Dropout\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 512)\n",
    "        self.up1 = Up(1024, 256)\n",
    "        self.up2 = Up(512, 128)\n",
    "        self.up3 = Up(256, 64)\n",
    "        self.up4 = Up(128, 64)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "# Initialize the model weights\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b45ae8a4-d9f0-4bf5-8a45-3ee93e28e0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27765/4037214090.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"unet_epoch_20.pth\"))  # Adjust filename if needed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (inc): Sequential(\n",
       "    (0): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outc): OutConv(\n",
       "    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained model (use the latest checkpoint)\n",
    "device = torch.device(\"cuda\")\n",
    "model = UNet(n_channels=3, n_classes=1).to(device)\n",
    "model.load_state_dict(torch.load(\"unet_epoch_20.pth\"))  # Adjust filename if needed\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36bf06d7-7797-49bd-a6d5-adff08705901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of loading a single test image\n",
    "test_image_filename = \"s3://solafune/test_images/images/test_0.tif\"  # Replace with your test image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10a87349-1d62-4937-a308-4b1a1cb0383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_test(test_image_filename):\n",
    "    # Load and preprocess the test image\n",
    "    image = load_image(test_image_filename)\n",
    "    original_shape = image.shape[:2]  # Capture the original shape of the image\n",
    "    image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    image = image.to(device)\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        output = model(image)\n",
    "        prediction = torch.sigmoid(output)  # Apply sigmoid to get probabilities\n",
    "        prediction = prediction.squeeze(0).cpu().numpy()  # Remove batch dimension and move to CPU\n",
    "    \n",
    "    threshold = 0.5\n",
    "    binary_mask = (prediction > threshold).astype(np.uint8)  # Apply threshold to get binary mask\n",
    "    \n",
    "    # Resize the binary mask to match the original image dimensions (if necessary)\n",
    "    binary_mask = F.interpolate(torch.tensor(binary_mask[0]).unsqueeze(0).unsqueeze(0).float(), size=original_shape, mode='bilinear', align_corners=False).squeeze().numpy()\n",
    "    \n",
    "    # Load the original image for visualization (without preprocessing)\n",
    "    original_image = load_image(test_image_filename)\n",
    "    \n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(original_image)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.imshow(binary_mask, cmap='gray')\n",
    "    \n",
    "    # Create a red colormap for the mask\n",
    "    red_cmap = ListedColormap(['black', 'red'])\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Original Image with Predicted Mask Overlay\")\n",
    "    plt.imshow(original_image)\n",
    "    plt.imshow(binary_mask, cmap=red_cmap, alpha=0.4)  # alpha controls the transparency of the mask\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2df13a6-360e-40e8-855c-902926efb739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_test(\"s3://solafune/test_images/images/test_0.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa59bc0-4e94-42ad-a43e-21dc86cf4c77",
   "metadata": {},
   "source": [
    "## Calling SAM2 to predict masks Using the Custom Class to predict using Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2027074-455a-45fe-9497-1f6e750cc72e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
